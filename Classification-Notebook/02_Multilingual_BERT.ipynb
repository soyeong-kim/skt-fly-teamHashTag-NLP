{"cells":[{"cell_type":"markdown","metadata":{"id":"VbbRZkK4r8Vv"},"source":["# Multilingual BERT (Google)\n","---\n","**모델 설명**<br>\n","- 구글에서 개발한 다국어 자연어처리 모델\n","\n","**모델 사이즈**<br>\n","-  vocab size = 11만\n","- 12-layer\n","\n","**학습 코퍼스**<br>\n","- 다국어(104개 언어)"]},{"cell_type":"markdown","metadata":{"id":"E73dKm84r45Q"},"source":["### 필요한 라이브러리 가져오기"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"xonDHEpFr773","executionInfo":{"status":"ok","timestamp":1685452584224,"user_tz":-540,"elapsed":3,"user":{"displayName":"김소영","userId":"03949757662449189055"}}},"outputs":[],"source":["# !pip install transformers"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"_yez999CsmvY","executionInfo":{"status":"ok","timestamp":1685452591817,"user_tz":-540,"elapsed":7154,"user":{"displayName":"김소영","userId":"03949757662449189055"}}},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import os\n","import random\n","\n","import torch\n","from torch import nn\n","from torch.utils.data import Dataset, DataLoader\n","\n","from transformers import BertTokenizer, BertModel\n","from transformers import get_linear_schedule_with_warmup\n","\n","from sklearn.preprocessing import LabelEncoder"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1685452591818,"user":{"displayName":"김소영","userId":"03949757662449189055"},"user_tz":-540},"id":"bT7lC-KNvfOn","outputId":"01d40b92-290a-4b4b-a6c5-4d5908d0a762"},"outputs":[{"output_type":"stream","name":"stdout","text":["cuda\n"]}],"source":["# GPU에서 학습하기\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print(device)"]},{"cell_type":"markdown","metadata":{"id":"cfh08kDMwAbE"},"source":["### 하이퍼 파라미터 세팅"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"K7KdU3N9wQ2t","executionInfo":{"status":"ok","timestamp":1685452591818,"user_tz":-540,"elapsed":5,"user":{"displayName":"김소영","userId":"03949757662449189055"}}},"outputs":[],"source":["CFG = {\n","    'EPOCHS': 2, \n","    'BATCH_SIZE': 8, \n","    'LEARNING_RATE': 1e-06, \n","    'SEED': 42\n","}"]},{"cell_type":"markdown","metadata":{"id":"Vr0T4bmTwuVe"},"source":["### SEED 고정하기\n","코드의 재현성을 위한 함수"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"Diii3IqlwQ8u","executionInfo":{"status":"ok","timestamp":1685452591819,"user_tz":-540,"elapsed":5,"user":{"displayName":"김소영","userId":"03949757662449189055"}}},"outputs":[],"source":["def seed_everything(seed):\n","    random.seed(seed)\n","    np.random.seed(seed)\n","    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.benchmark = True"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"kgMcK2P6yHTN","executionInfo":{"status":"ok","timestamp":1685452591819,"user_tz":-540,"elapsed":5,"user":{"displayName":"김소영","userId":"03949757662449189055"}}},"outputs":[],"source":["seed_everything(CFG['SEED'])"]},{"cell_type":"markdown","metadata":{"id":"uXaw4lROyd2V"},"source":["### 1. 데이터 준비\n","- AI-Hub: 주제별 텍스트 일상 대화 데이터\n","- 20개 주제 중에서 10개 주제(식음료, 회사/아르바이트, 교육, 가족, 연애/결혼, 반려동물, 스포츠/레저, 여행, 미용, 영화/만화)의 데이터를 사용함"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"VJ9DFIl4sSW3","executionInfo":{"status":"ok","timestamp":1685452593459,"user_tz":-540,"elapsed":1645,"user":{"displayName":"김소영","userId":"03949757662449189055"}}},"outputs":[],"source":["train_df = pd.read_csv('/content/drive/MyDrive/classification_model/data/train.csv')\n","valid_df = pd.read_csv('/content/drive/MyDrive/classification_model/data/valid.csv')"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":239},"executionInfo":{"elapsed":30,"status":"ok","timestamp":1685452593460,"user":{"displayName":"김소영","userId":"03949757662449189055"},"user_tz":-540},"id":"wIVLyq4arqvx","outputId":"021ae4bb-99eb-4bd1-ea1a-2e9ceed46841"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                                text  label\n","0  이영애 새 드라마 보신 분 이영애 새 드라마 나와 난 방송은 못 믿겠더라 맛집 소개...  방송/연예\n","1  엄마 10월 그리고리 영화봤어요 아니 그게 뭔지 몰라 죽기 전에 봐야 할 영화 2번...  영화/만화\n","2  내가 곰곰이 생각해 보니 우리 가족은 웃음이 없는 것 같아요 나도 그렇게 생각했는데...     가족"],"text/html":["\n","  <div id=\"df-f4fd3740-10d4-416f-a82c-78619db9934e\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>이영애 새 드라마 보신 분 이영애 새 드라마 나와 난 방송은 못 믿겠더라 맛집 소개...</td>\n","      <td>방송/연예</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>엄마 10월 그리고리 영화봤어요 아니 그게 뭔지 몰라 죽기 전에 봐야 할 영화 2번...</td>\n","      <td>영화/만화</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>내가 곰곰이 생각해 보니 우리 가족은 웃음이 없는 것 같아요 나도 그렇게 생각했는데...</td>\n","      <td>가족</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f4fd3740-10d4-416f-a82c-78619db9934e')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-f4fd3740-10d4-416f-a82c-78619db9934e button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-f4fd3740-10d4-416f-a82c-78619db9934e');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":8}],"source":["train_df.head(3)"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":222},"executionInfo":{"elapsed":29,"status":"ok","timestamp":1685452593461,"user":{"displayName":"김소영","userId":"03949757662449189055"},"user_tz":-540},"id":"qikME4lUr1lP","outputId":"78ec2616-56ae-4491-cc77-270c68768f66"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                                text  label\n","0  언니 지금 비타민 챙겨 먹고 있어 웅 챙겨 먹어 나이가 있어서 맞아 20대 때부터 ...     건강\n","1  여행사 껴서 여행 가는 거 생각보다 괜찮더라 맞아 나도 가끔 가는데 일정 생각 안하...     여행\n","2  재밌는 영화 추천 좀 해봐 키키 요새 영화 안 본지 오래됨 나두 그래 너무 재밌는 ...  영화/만화"],"text/html":["\n","  <div id=\"df-8211fe73-9717-4349-8176-f8738c1303b4\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>언니 지금 비타민 챙겨 먹고 있어 웅 챙겨 먹어 나이가 있어서 맞아 20대 때부터 ...</td>\n","      <td>건강</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>여행사 껴서 여행 가는 거 생각보다 괜찮더라 맞아 나도 가끔 가는데 일정 생각 안하...</td>\n","      <td>여행</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>재밌는 영화 추천 좀 해봐 키키 요새 영화 안 본지 오래됨 나두 그래 너무 재밌는 ...</td>\n","      <td>영화/만화</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8211fe73-9717-4349-8176-f8738c1303b4')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-8211fe73-9717-4349-8176-f8738c1303b4 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-8211fe73-9717-4349-8176-f8738c1303b4');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":9}],"source":["valid_df.head(3)"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"OuD154ebOZ17","executionInfo":{"status":"ok","timestamp":1685452593462,"user_tz":-540,"elapsed":29,"user":{"displayName":"김소영","userId":"03949757662449189055"}}},"outputs":[],"source":["label_list = ['영화/만화', '가족', '식음료', '교육', '회사/아르바이트', '스포츠/레저', '연애/결혼', '반려동물', '여행', '미용']\n","\n","train_df = train_df[train_df['label'].isin(label_list)].reset_index(drop=True)\n","valid_df = valid_df[valid_df['label'].isin(label_list)].reset_index(drop=True)"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":28,"status":"ok","timestamp":1685452593462,"user":{"displayName":"김소영","userId":"03949757662449189055"},"user_tz":-540},"id":"KSZRcBJYA-F1","outputId":"10eda23a-78df-4984-a60b-51ec0afc42d1"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["array(['영화/만화', '가족', '식음료', '교육', '회사/아르바이트', '스포츠/레저', '연애/결혼', '반려동물',\n","       '여행', '미용'], dtype=object)"]},"metadata":{},"execution_count":11}],"source":["train_df['label'].unique()"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":25,"status":"ok","timestamp":1685452593462,"user":{"displayName":"김소영","userId":"03949757662449189055"},"user_tz":-540},"id":"k0xTlS-BBNqi","outputId":"d703f65d-b346-40c1-fc77-2dbd678d7c1e"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["10"]},"metadata":{},"execution_count":12}],"source":["len(train_df['label'].unique())"]},{"cell_type":"markdown","metadata":{"id":"npHA9qJGyjJ0"},"source":["라벨 인코딩"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"jrsBcFoir1oP","executionInfo":{"status":"ok","timestamp":1685452593463,"user_tz":-540,"elapsed":23,"user":{"displayName":"김소영","userId":"03949757662449189055"}}},"outputs":[],"source":["le = LabelEncoder()\n","train_df['label'] = le.fit_transform(train_df['label'])\n","valid_df['label'] = le.transform(valid_df['label'])"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"1lcwfLJ0uEyK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1685452593463,"user_tz":-540,"elapsed":22,"user":{"displayName":"김소영","userId":"03949757662449189055"}},"outputId":"95f55d86-2bc5-4f93-9aac-38882223a8cf"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["array(['가족', '교육', '미용', '반려동물', '스포츠/레저', '식음료', '여행', '연애/결혼', '영화/만화',\n","       '회사/아르바이트'], dtype=object)"]},"metadata":{},"execution_count":14}],"source":["# 변환된 label classes 확인\n","le.classes_"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":250},"executionInfo":{"elapsed":20,"status":"ok","timestamp":1685452593463,"user":{"displayName":"김소영","userId":"03949757662449189055"},"user_tz":-540},"id":"etOpeAUkt822","outputId":"3cd3787d-ca1c-483d-db17-c48849eb2e0d"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                                text  label\n","0  엄마 10월 그리고리 영화봤어요 아니 그게 뭔지 몰라 죽기 전에 봐야 할 영화 2번...      8\n","1  내가 곰곰이 생각해 보니 우리 가족은 웃음이 없는 것 같아요 나도 그렇게 생각했는데...      0\n","2  오늘 하루도 잘 보냈니 내일 출근 전 아침 메뉴 하나 추천해줘 너도 잘 보냈냐 너 ...      5\n","3  나도 만화가 되고싶다 나도 만화 잘 그리고 싶어 어렸을떄 애들이 만화 많이 그렸는데...      8\n","4  는 날 닮은 것 같지 응 자기 닮았지 엄마도 내 어린시절을 많이 닮았다고 하셔 하하...      0"],"text/html":["\n","  <div id=\"df-84cd1793-ab1a-4917-86d5-d672f26162ff\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>엄마 10월 그리고리 영화봤어요 아니 그게 뭔지 몰라 죽기 전에 봐야 할 영화 2번...</td>\n","      <td>8</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>내가 곰곰이 생각해 보니 우리 가족은 웃음이 없는 것 같아요 나도 그렇게 생각했는데...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>오늘 하루도 잘 보냈니 내일 출근 전 아침 메뉴 하나 추천해줘 너도 잘 보냈냐 너 ...</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>나도 만화가 되고싶다 나도 만화 잘 그리고 싶어 어렸을떄 애들이 만화 많이 그렸는데...</td>\n","      <td>8</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>는 날 닮은 것 같지 응 자기 닮았지 엄마도 내 어린시절을 많이 닮았다고 하셔 하하...</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-84cd1793-ab1a-4917-86d5-d672f26162ff')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-84cd1793-ab1a-4917-86d5-d672f26162ff button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-84cd1793-ab1a-4917-86d5-d672f26162ff');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":15}],"source":["train_df.head()"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18,"status":"ok","timestamp":1685452593463,"user":{"displayName":"김소영","userId":"03949757662449189055"},"user_tz":-540},"id":"Try5k4-Xs02t","outputId":"ce5edc64-9b8f-45ac-daa0-9ab85e399ba1"},"outputs":[{"output_type":"stream","name":"stdout","text":["{0: '가족', 1: '교육', 2: '미용', 3: '반려동물', 4: '스포츠/레저', 5: '식음료', 6: '여행', 7: '연애/결혼', 8: '영화/만화', 9: '회사/아르바이트'}\n"]}],"source":["LABEL_COLUMNS = {i: label for i, label in enumerate(le.classes_)}\n","print(LABEL_COLUMNS)"]},{"cell_type":"markdown","metadata":{"id":"OnlkJ4hS3wBE"},"source":["### 2. BERT Tokenizer 🤗\n","- CustomDataset 클래스"]},{"cell_type":"code","execution_count":17,"metadata":{"executionInfo":{"elapsed":10799,"status":"ok","timestamp":1685452604246,"user":{"displayName":"김소영","userId":"03949757662449189055"},"user_tz":-540},"id":"OSs3DSVR3yzO"},"outputs":[],"source":["tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased',\n","                                          do_lower_case=False)"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"scvLiFqVt85u","executionInfo":{"status":"ok","timestamp":1685452604247,"user_tz":-540,"elapsed":18,"user":{"displayName":"김소영","userId":"03949757662449189055"}}},"outputs":[],"source":["class CustomDataset(Dataset):\n","    def __init__(self, df, tokenizer, max_len):\n","        self.df = df\n","        self.tokenizer = tokenizer\n","        self.max_len = max_len\n","    \n","    def __len__(self):\n","        return len(self.df)\n","    \n","    def __getitem__(self, idx):\n","        text = self.df.loc[idx, 'text']\n","        label = self.df.loc[idx, 'label']\n","        \n","        encoded_dict = self.tokenizer.encode_plus(\n","            text=text, # Sequence to encode\n","            add_special_tokens=True, # Add '[CLS]' and '[SEP]'\n","            max_length=self.max_len, \n","            padding='max_length', # Pad and truncate\n","            truncation=True, #Truncate the seq\n","            return_attention_mask=True, # Construct attn. masks\n","            return_token_type_ids=False, \n","            return_tensors='pt' # Return pytorch tensors\n","        )\n","\n","        return dict(\n","            text = text, \n","            input_ids = encoded_dict['input_ids'].flatten(), \n","            attention_mask = encoded_dict['attention_mask'].flatten(), \n","            label = torch.tensor(label)\n","        )"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"ZPh8pVM9PnHc","executionInfo":{"status":"ok","timestamp":1685452604248,"user_tz":-540,"elapsed":17,"user":{"displayName":"김소영","userId":"03949757662449189055"}}},"outputs":[],"source":["MAX_LEN = 512\n","\n","train_dataset = CustomDataset(train_df, tokenizer, MAX_LEN)\n","valid_dataset = CustomDataset(valid_df, tokenizer, MAX_LEN)"]},{"cell_type":"code","execution_count":20,"metadata":{"id":"K4SSYxGztuFI","executionInfo":{"status":"ok","timestamp":1685452604248,"user_tz":-540,"elapsed":15,"user":{"displayName":"김소영","userId":"03949757662449189055"}}},"outputs":[],"source":["train_dataloader = DataLoader(\n","    train_dataset, \n","    batch_size = CFG['BATCH_SIZE'], \n","    shuffle = True, \n","    num_workers = 2)\n","\n","valid_dataloader = DataLoader(\n","    valid_dataset, \n","    batch_size = CFG['BATCH_SIZE'], \n","    shuffle = True, \n","    num_workers = 2)"]},{"cell_type":"markdown","metadata":{"id":"mZaBMPUg3oDl"},"source":["### 3. BERT Model 🤗\n","- BaseModel 클래스"]},{"cell_type":"code","execution_count":21,"metadata":{"id":"7Lfups-JtuHu","executionInfo":{"status":"ok","timestamp":1685452604249,"user_tz":-540,"elapsed":15,"user":{"displayName":"김소영","userId":"03949757662449189055"}}},"outputs":[],"source":["class BaseModel(nn.Module):\n","    def __init__(self, num_classes=len(le.classes_)):\n","        super(BaseModel, self).__init__()\n","        self.model = BertModel.from_pretrained('bert-base-multilingual-cased')\n","        self.dropout = nn.Dropout(0.3)\n","        self.linear = nn.Linear(768, num_classes)\n","\n","    def forward(self, input_ids, attention_mask):\n","        outputs = self.model(input_ids=input_ids, attention_mask=attention_mask)\n","        last_hidden_state = outputs.last_hidden_state\n","        cls_token = last_hidden_state[:, 0, :]\n","        x = self.dropout(cls_token)\n","        output = self.linear(x)\n","        \n","        return output"]},{"cell_type":"code","execution_count":22,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5511,"status":"ok","timestamp":1685452609745,"user":{"displayName":"김소영","userId":"03949757662449189055"},"user_tz":-540},"id":"Ad8YGgfj7tkS","outputId":"f69e5318-e43d-4014-bbd3-2ef86b3bae06"},"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"execute_result","data":{"text/plain":["BaseModel(\n","  (model): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0-11): 12 x BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (dropout): Dropout(p=0.3, inplace=False)\n","  (linear): Linear(in_features=768, out_features=10, bias=True)\n",")"]},"metadata":{},"execution_count":22}],"source":["model = BaseModel()\n","model.to(device)"]},{"cell_type":"markdown","metadata":{"id":"7V-3ra8mZRr7"},"source":["### 4. 학습(Train) & 평가(Evaluation)"]},{"cell_type":"code","execution_count":23,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14,"status":"ok","timestamp":1685452609745,"user":{"displayName":"김소영","userId":"03949757662449189055"},"user_tz":-540},"id":"WJFAvQVAN1DJ","outputId":"dc77aa70-22f4-4bba-cd67-573b8ddd07ca"},"outputs":[{"output_type":"stream","name":"stdout","text":["Create a model save folder...\n"]}],"source":["# 폴더 생성\n","path = 'model'\n","\n","print(f'Create a model save folder...')\n","if not os.path.isdir(path):\n","    os.mkdir(path)"]},{"cell_type":"code","execution_count":24,"metadata":{"id":"CkPr6SCOTtaK","executionInfo":{"status":"ok","timestamp":1685452609746,"user_tz":-540,"elapsed":8,"user":{"displayName":"김소영","userId":"03949757662449189055"}}},"outputs":[],"source":["# 손실 함수 설정\n","loss_fn = nn.CrossEntropyLoss()\n","\n","# 옵티마이저 설정\n","optimizer = torch.optim.AdamW(model.parameters(), lr=CFG['LEARNING_RATE'], eps=1e-8)\n","\n","# 총 훈련 스텝으로 배치반복 횟수 * 에폭\n","total_steps = len(train_dataloader) * CFG['EPOCHS']\n","\n","# 학습률을 변화시키는 스케줄러\n","scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps = 0, num_training_steps = total_steps)"]},{"cell_type":"code","execution_count":25,"metadata":{"id":"v2OHlJ5IccpT","executionInfo":{"status":"ok","timestamp":1685452609746,"user_tz":-540,"elapsed":7,"user":{"displayName":"김소영","userId":"03949757662449189055"}}},"outputs":[],"source":["# 정확도 계산 함수\n","def flat_accuracy(preds, labels):\n","    pred_flat = np.argmax(preds, axis=1).flatten()\n","    labels_flat = labels.flatten()\n","    \n","    return np.sum(pred_flat == labels_flat) / len(labels_flat)"]},{"cell_type":"code","execution_count":26,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8925894,"status":"ok","timestamp":1685461535633,"user":{"displayName":"김소영","userId":"03949757662449189055"},"user_tz":-540},"id":"EiBzJcdc_-jB","outputId":"4ab78b14-7504-4896-8770-176bcfd70b84"},"outputs":[{"output_type":"stream","name":"stdout","text":["======== Epoch 1 / 2 ========\n","Training...\n","Batch     0 of 5,571 | Train Loss: 2.484\n","Batch 1,000 of 5,571 | Train Loss: 1.519\n","Batch 2,000 of 5,571 | Train Loss: 0.685\n","Batch 3,000 of 5,571 | Train Loss: 2.847\n","Batch 4,000 of 5,571 | Train Loss: 0.608\n","Batch 5,000 of 5,571 | Train Loss: 0.837\n","Average Train Loss: 0.797\n","\n","Running Validation...\n","Average Validation Loss: 0.354\n","Validation Accuracy: 0.899\n","======== Epoch 2 / 2 ========\n","Training...\n","Batch     0 of 5,571 | Train Loss: 0.153\n","Batch 1,000 of 5,571 | Train Loss: 0.041\n","Batch 2,000 of 5,571 | Train Loss: 0.160\n","Batch 3,000 of 5,571 | Train Loss: 0.716\n","Batch 4,000 of 5,571 | Train Loss: 0.103\n","Batch 5,000 of 5,571 | Train Loss: 0.019\n","Average Train Loss: 0.400\n","\n","Running Validation...\n","Average Validation Loss: 0.340\n","Validation Accuracy: 0.910\n"]}],"source":["for epoch in range(CFG['EPOCHS']):\n","    # ----------------------Training----------------------\n","    print('======== Epoch {:} / {:} ========'.format(epoch + 1, CFG['EPOCHS']))\n","    print('Training...')\n","    \n","    model.train() # 학습 모드\n","    \n","    total_train_loss = 0\n","    \n","    for step, batch in enumerate(train_dataloader, 0):\n","        b_input_ids = batch['input_ids'].to(device, dtype = torch.long)\n","        b_input_mask = batch['attention_mask'].to(device, dtype = torch.long)\n","        b_labels = batch['label'].to(device, dtype = torch.long)\n","\n","        optimizer.zero_grad() # optimizer 초기화\n","        outputs = model(b_input_ids, b_input_mask)\n","\n","        loss = loss_fn(outputs, b_labels)\n","\n","        loss.backward() # loss의 역전파\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0) # gradient clipping(exploding gradient problem 방지)\n","        optimizer.step() # optimizer 가중치 업데이트\n","        scheduler.step() # Update learning rate schedule\n","\n","        total_train_loss += loss.item() # 총 loss 계산\n","\n","        if step % 1000 == 0:\n","            print('Batch {:>5,} of {:>5,} | Train Loss: {:.3f}'.format(step, len(train_dataloader), loss.item()))\n","\n","    avg_train_loss = total_train_loss / len(train_dataloader)\n","    print(\"Average Train Loss: {:.3f}\".format(avg_train_loss))\n","    \n","    # ----------------------Validation----------------------\n","    print(\"\")\n","    print(\"Running Validation...\")\n","    \n","    model.eval() # 평가 모드\n","    \n","    total_eval_loss = 0\n","    total_eval_acc = 0\n","\n","    for step, batch in enumerate(valid_dataloader, 0):\n","        with torch.no_grad(): # gradient 계산 안함\n","            b_input_ids = batch['input_ids'].to(device, dtype = torch.long)\n","            b_input_mask = batch['attention_mask'].to(device, dtype = torch.long)\n","            b_labels = batch['label'].to(device, dtype = torch.long)\n","\n","            outputs = model(b_input_ids, b_input_mask)\n","\n","            loss = loss_fn(outputs, b_labels)\n","\n","            total_eval_loss += loss.item() # 총 loss 계산\n","\n","            # CPU 데이터\n","            outputs = outputs.detach().cpu().numpy()\n","            b_labels = b_labels.to('cpu').numpy()\n","\n","            total_eval_acc += flat_accuracy(outputs, b_labels)\n","    \n","    print(\"Average Validation Loss: {:.3f}\".format(total_eval_loss / len(valid_dataloader)))\n","    print(\"Validation Accuracy: {:.3f}\".format(total_eval_acc / len(valid_dataloader)))\n","    \n","    PATH = f'model/classification_model_{epoch + 1}.pt'\n","    torch.save(model.state_dict(), PATH)"]},{"cell_type":"markdown","metadata":{"id":"3dU0K4gghnxZ"},"source":["|Epoch|Train Loss|Val loss|Val acc|\n","|:---:|:---:|:---:|:---:|\n","|1|0.797|0.354|0.899|\n","|2|0.400|0.340|0.910|"]},{"cell_type":"markdown","metadata":{"id":"FTdCpdrAsX-j"},"source":["### 5. 추론(Inference)\n","- 추론을 위해 모델 저장하고 불러오기\n","- 저장한 모델을 불러와서 예측하기"]},{"cell_type":"code","execution_count":27,"metadata":{"id":"rebgnmmLcxdg","executionInfo":{"status":"ok","timestamp":1685461538534,"user_tz":-540,"elapsed":2915,"user":{"displayName":"김소영","userId":"03949757662449189055"}}},"outputs":[],"source":["# 모델 저장하기\n","PATH = 'model/classification_model.pt'\n","torch.save(model.state_dict(), PATH)"]},{"cell_type":"code","execution_count":28,"metadata":{"id":"JmPmGFaJsqFp","executionInfo":{"status":"ok","timestamp":1685461538535,"user_tz":-540,"elapsed":8,"user":{"displayName":"김소영","userId":"03949757662449189055"}}},"outputs":[],"source":["class BaseModel(nn.Module):\n","    def __init__(self, num_classes=10):\n","        super(BaseModel, self).__init__()\n","        self.model = BertModel.from_pretrained('bert-base-multilingual-cased')\n","        self.dropout = nn.Dropout(0.3)\n","        self.linear = nn.Linear(768, num_classes)\n","\n","    def forward(self, input_ids, attention_mask):\n","        outputs = self.model(input_ids=input_ids, attention_mask=attention_mask)\n","        last_hidden_state = outputs.last_hidden_state\n","        cls_token = last_hidden_state[:, 0, :]\n","        x = self.dropout(cls_token)\n","        output = self.linear(x)\n","        \n","        return output"]},{"cell_type":"code","execution_count":29,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2962,"status":"ok","timestamp":1685461541489,"user":{"displayName":"김소영","userId":"03949757662449189055"},"user_tz":-540},"id":"avke7GC5swdp","outputId":"b46dff4e-ad5c-4438-cb32-5bc12d518e5c"},"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"execute_result","data":{"text/plain":["BaseModel(\n","  (model): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0-11): 12 x BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (dropout): Dropout(p=0.3, inplace=False)\n","  (linear): Linear(in_features=768, out_features=10, bias=True)\n",")"]},"metadata":{},"execution_count":29}],"source":["# 모델 불러오기\n","PATH = 'model/classification_model.pt'\n","\n","device = torch.device('cuda')\n","model = BaseModel()\n","model.load_state_dict(torch.load(PATH))\n","model.to(device)"]},{"cell_type":"code","execution_count":30,"metadata":{"id":"zvWzva-new_b","executionInfo":{"status":"ok","timestamp":1685461541490,"user_tz":-540,"elapsed":5,"user":{"displayName":"김소영","userId":"03949757662449189055"}}},"outputs":[],"source":["def predict(tokenizer, label_columns, sent_list):\n","    text = ' '.join(sent_list)\n","    \n","    encoded_dict = tokenizer.encode_plus(\n","        text=text, # Sequence to encode\n","        add_special_tokens=True, # Add '[CLS]' and '[SEP]'\n","        max_length=512, \n","        padding='max_length', # Pad and truncate\n","        truncation=True, #Truncate the seq\n","        return_attention_mask=True, # Construct attn. masks\n","        return_token_type_ids=False, \n","        return_tensors='pt' # Return pytorch tensors\n","    )\n","\n","    model.eval()\n","\n","    input_ids = encoded_dict['input_ids'].long().to(device)\n","    input_mask = encoded_dict['attention_mask'].long().to(device)\n","    \n","    output = model(input_ids, input_mask)\n","\n","    print(f\"모델의 Output:\\n {output}\")\n","    print(f\"Softmax를 통과한 Output:\\n {nn.Softmax(dim=1)(output)}\")\n","\n","    output = output.detach().cpu().numpy()\n","    pred = np.argmax(output)\n","\n","    return label_columns[pred]"]},{"cell_type":"code","execution_count":33,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":162},"executionInfo":{"elapsed":410,"status":"ok","timestamp":1685462176750,"user":{"displayName":"김소영","userId":"03949757662449189055"},"user_tz":-540},"id":"-KuLXmEWfp1M","outputId":"e732e7da-67fd-46d2-88f5-50302c2328af"},"outputs":[{"output_type":"stream","name":"stdout","text":["모델의 Output:\n"," tensor([[-0.5934, -1.3689, -0.0824, -0.7619, -0.6494,  5.8656, -0.3038, -0.4132,\n","         -1.4283, -0.7134]], device='cuda:0', grad_fn=<AddmmBackward0>)\n","Softmax를 통과한 Output:\n"," tensor([[1.5450e-03, 7.1145e-04, 2.5757e-03, 1.3054e-03, 1.4610e-03, 9.8645e-01,\n","         2.0642e-03, 1.8503e-03, 6.7048e-04, 1.3704e-03]], device='cuda:0',\n","       grad_fn=<SoftmaxBackward0>)\n"]},{"output_type":"execute_result","data":{"text/plain":["'식음료'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":33}],"source":["tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased',\n","                                          do_lower_case=False)\n","\n","label_columns = ['가족', '교육', '미용', '반려동물', '스포츠/레저', '식음료', '여행', '연애/결혼', '영화/만화', '회사/아르바이트']\n","\n","sent_list = ['오늘 점심으로 토스트와 커피를 먹을거예요', \n","             '토스트를 구매하고 커피를 사러 갈거예요', \n","             '아이스아메리카노 한잔 주세요']\n","\n","predict(tokenizer, label_columns, sent_list)"]},{"cell_type":"code","execution_count":34,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":162},"executionInfo":{"elapsed":313,"status":"ok","timestamp":1685462220631,"user":{"displayName":"김소영","userId":"03949757662449189055"},"user_tz":-540},"id":"MOyTvzaX5yQ7","outputId":"1aa0cee2-7078-4924-dde9-ec87ee992d75"},"outputs":[{"output_type":"stream","name":"stdout","text":["모델의 Output:\n"," tensor([[-0.3285, -0.3316, -0.7047,  6.5010, -0.7961, -1.0644,  0.2368, -0.8782,\n","         -0.5075, -0.9096]], device='cuda:0', grad_fn=<AddmmBackward0>)\n","Softmax를 통과한 Output:\n"," tensor([[1.0726e-03, 1.0693e-03, 7.3637e-04, 9.9193e-01, 6.7204e-04, 5.1390e-04,\n","         1.8879e-03, 6.1905e-04, 8.9688e-04, 5.9994e-04]], device='cuda:0',\n","       grad_fn=<SoftmaxBackward0>)\n"]},{"output_type":"execute_result","data":{"text/plain":["'반려동물'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":34}],"source":["tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased',\n","                                          do_lower_case=False)\n","\n","label_columns = ['가족', '교육', '미용', '반려동물', '스포츠/레저', '식음료', '여행', '연애/결혼', '영화/만화', '회사/아르바이트']\n","\n","sent_list = ['우리 댕댕이 귀여워', '강아지랑 산책 중이예요']\n","\n","predict(tokenizer, label_columns, sent_list)"]},{"cell_type":"markdown","metadata":{"id":"vKpq-t5amXT-"},"source":["### END"]}],"metadata":{"accelerator":"GPU","colab":{"machine_shape":"hm","provenance":[],"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"}},"nbformat":4,"nbformat_minor":0}